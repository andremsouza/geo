{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2json\n",
    "import json\n",
    "import psycopg2\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from os import listdir, getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=35.192.163.239 port=5432 dbname=testdb user=%s password=%s\" % (input(\"User: \"), getpass.getpass(\"Password: \")))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Seq Scan on textarrtest  (cost=0.00..11.73 rows=1 width=4) (actual rows=1 loops=1)',)\n",
      "(\"  Filter: (to_tsvector('portuguese'::regconfig, texto) @@ '''nasc'' <2> ''londrin'''::tsquery)\",)\n",
      "('  Rows Removed by Filter: 17',)\n",
      "('Planning time: 0.133 ms',)\n",
      "('Execution time: 159.029 ms',)\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"EXPLAIN (ANALYZE TRUE, TIMING FALSE) SELECT ID FROM TEXTARRTEST\n",
    "            WHERE to_tsvector('portuguese', TEXTO) @@ phraseto_tsquery('portuguese', 'nasci em londrina');\"\"\")\n",
    "print(*cur.fetchall(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating textsearch column and index\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"\"\"ALTER TABLE TEXTARRTEST ADD COLUMN textsearch_index_col tsvector;\"\"\")\n",
    "# cur.execute(\"\"\"UPDATE textarrtest SET textsearch_index_col = to_tsvector('portuguese', coalesce(texto, ''));\"\"\")\n",
    "# cur.execute(\"\"\"CREATE INDEX idx_textarrtest_textsearch ON textarrtest USING GIN (textsearch_index_col);\"\"\")\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bitmap Heap Scan on textarrtest  (cost=20.08..27.54 rows=10 width=4) (actual rows=1 loops=1)',)\n",
      "(\"  Recheck Cond: (textsearch_index_col @@ '''nasc'' <2> ''londrin'''::tsquery)\",)\n",
      "('  Rows Removed by Index Recheck: 9',)\n",
      "('  Heap Blocks: exact=3',)\n",
      "('  ->  Bitmap Index Scan on idx_textarrtest_textsearch  (cost=0.00..20.08 rows=10 width=0) (actual rows=10 loops=1)',)\n",
      "(\"        Index Cond: (textsearch_index_col @@ '''nasc'' <2> ''londrin'''::tsquery)\",)\n",
      "('Planning time: 0.208 ms',)\n",
      "('Execution time: 0.260 ms',)\n"
     ]
    }
   ],
   "source": [
    "# Forcing index usage for testing purposes\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SET enable_seqscan = off;\"\"\")\n",
    "cur.execute(\"\"\"EXPLAIN (ANALYZE TRUE, TIMING FALSE) SELECT ID FROM TEXTARRTEST\n",
    "            WHERE textsearch_index_col @@ phraseto_tsquery('portuguese', 'nasci em londrina');\"\"\")\n",
    "print(*cur.fetchall(), sep='\\n')\n",
    "cur.execute(\"\"\"SET enable_seqscan = on;\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating trigger for textsearch column\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"CREATE TRIGGER trig_textarrtest_textsearchupdate BEFORE INSERT OR UPDATE\n",
    "            ON textarrtest FOR EACH ROW EXECUTE PROCEDURE\n",
    "            tsvector_update_trigger(textsearch_index_col, 'pg_catalog.portuguese', texto);\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('é', 18, 2631)\n",
      "('assim', 18, 1681)\n",
      "('gent', 18, 1630)\n",
      "('pra', 18, 1409)\n",
      "('entã', 18, 1174)\n",
      "('porqu', 18, 985)\n",
      "('aí', 16, 940)\n",
      "('trein', 18, 738)\n",
      "('faz', 18, 690)\n",
      "('fal', 18, 678)\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT * FROM ts_stat('SELECT textsearch_index_col FROM textarrtest')\n",
    "            ORDER BY nentry DESC, ndoc DESC, word ASC\n",
    "            LIMIT 10;\"\"\")\n",
    "print(*cur.fetchall(), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
